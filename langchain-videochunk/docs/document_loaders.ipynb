{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: VideoChunkLoader\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VideoChunkLoader\n",
    "\n",
    "This notebook provides a quick overview for getting started with VideoChunkLoader [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all VideoChunkLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.langchain_videochunk_loader.VideoChunkLoader.html).\n",
    "\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/langchain_videochunk_loader)|\n",
    "| :--- | :--- | :---: | :---: |  :---: |\n",
    "| [VideoChunkLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.langchain_videochunkloader.VideoChunkLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅/❌ | beta/❌ | ✅/❌ | \n",
    "### Loader features\n",
    "| Source | Document Lazy Loading | Native Async Support\n",
    "| :---: | :---: | :---: | \n",
    "| VideoChunkLoader | ✅/❌ | ✅/❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access VideoChunkLoader document loader you'll need to install the `langchain-videochunk` integration package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48afb8d",
   "metadata": {
    "id": "e48afb8d"
   },
   "source": [
    "# Local Video Ingestion for VLM summarization\n",
    "\n",
    "Building video summarization or QA applications on you're local videos is a topic of high interest. Current Large Vision Language models (VLMs) can only utilize a finite set of frames to represent any given video - this is usually between 8 and 64 frames sampled from an input video, but varies by model. This means that for accurate transcription of long form videos, a chunking mechanism is required to trim videos into smaller clips such that the finite set of frames better represents the video that is being used as visual input to the VLM.\n",
    "\n",
    "Below we show how to easily go from an `.mp4` file to chunked clips used for more accurate LVM video summarizations that can used in downstream tasks including RAG applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install **langchain_community**.\n",
    "\n",
    "- FFMpeg",
    "- Download sample video via wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain_community"
   ]
  },
   {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install wget ffmpeg -y\n",
    "!wget -O sample_video.mp4 \"https://github.com/intel-iot-devkit/sample-videos/raw/master/store-aisle-detection.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6b49",
   "metadata": {
    "id": "93be6b49"
   },
   "source": [
    "## Building a video summarization app from local sample video\n",
    "\n",
    "Given `sample_video.mp4`, we can enable ingestion meant for video summarization. Below we will show the two different ingestion mechanisms provided by VideoChunkLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11f4d6-2fec-4945-a9d9-1f12cc334876",
   "metadata": {},
   "source": [
    "### Example of \"Sliding Window\" with overlap implementation\n",
    "\n",
    "To overcome the issue of losing context at start and end of clips, we allow the user to configure a sliding window techinique that includes an overlap to address the missing context at clip start/endpoints."
   ]
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Now we can instantiate our model object and load documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import VideoChunkLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33648d9d-b92d-487a-9ec4-977f05a2c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk metadata: {'chunk_id': 0, 'chunk_path': 'video_chunks/chunk_0.mp4', 'start_time': 0, 'end_time': 10, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 0s to 10s\n",
      "Chunk metadata: {'chunk_id': 1, 'chunk_path': 'video_chunks/chunk_1.mp4', 'start_time': 8, 'end_time': 18, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 8s to 18s\n",
      "Chunk metadata: {'chunk_id': 2, 'chunk_path': 'video_chunks/chunk_2.mp4', 'start_time': 16, 'end_time': 26, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 16s to 26s\n",
      "Chunk metadata: {'chunk_id': 3, 'chunk_path': 'video_chunks/chunk_3.mp4', 'start_time': 24, 'end_time': 34, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 24s to 34s\n",
      "Chunk metadata: {'chunk_id': 4, 'chunk_path': 'video_chunks/chunk_4.mp4', 'start_time': 32, 'end_time': 42, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 32s to 42s\n",
      "Chunk metadata: {'chunk_id': 5, 'chunk_path': 'video_chunks/chunk_5.mp4', 'start_time': 40, 'end_time': 50, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 40s to 50s\n",
      "Chunk metadata: {'chunk_id': 6, 'chunk_path': 'video_chunks/chunk_6.mp4', 'start_time': 48, 'end_time': 58, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 48s to 58s\n",
      "Chunk metadata: {'chunk_id': 7, 'chunk_path': 'video_chunks/chunk_7.mp4', 'start_time': 56, 'end_time': 65.415375, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 56s to 65.415375s\n",
      "Chunk metadata: {'chunk_id': 8, 'chunk_path': 'video_chunks/chunk_8.mp4', 'start_time': 64, 'end_time': 65.415375, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 64s to 65.415375s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"video_chunks/chunk_0.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load \n",
    "# VideoChunkLoader object for ingesting video, using the sliding window technique\n",
    "loader = VideoChunkLoader(\n",
    "    video_path=video_path,\n",
    "    chunking_mechanism=\"sliding_window\",\n",
    "    chunk_duration=10,\n",
    "    chunk_overlap=2\n",
    ")\n",
    "\n",
    "# Display the langchain documents created after loading the sample video, the video chunks are saved in the 'video_chunks' directory\n",
    "for doc in loader.lazy_load():\n",
    "    print(f\"Chunk metadata: {doc.metadata}\")\n",
    "    print(f\"Chunk content: {doc.page_content}\")\n",
    "\n",
    "# Playback of the first interval chunked video, should have length 'chunk_duration'\n",
    "Video('video_chunks/chunk_0.mp4', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06690c16-6137-4234-a33b-606a27765012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk metadata: {'chunk_id': 0, 'chunk_path': 'video_chunks/chunk_0.mp4', 'start_time': 10, 'end_time': 20, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 10s to 20s\n",
      "Chunk metadata: {'chunk_id': 1, 'chunk_path': 'video_chunks/chunk_1.mp4', 'start_time': 20, 'end_time': 28, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 20s to 28s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"video_chunks/chunk_0.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup VideoChunkLoader object for ingesting video, using the specific itervals technique\n",
    "loader = VideoChunkLoader(\n",
    "    video_path=video_path,\n",
    "    chunking_mechanism=\"specific_chunks\",\n",
    "    specific_intervals=[\n",
    "        {\"start\": 10, \"duration\": 10},\n",
    "        {\"start\": 20, \"duration\": 8}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the langchain documents created after loading the sample video, the video chunks are saved in the 'video_chunks' directory\n",
    "for doc in loader.lazy_load():\n",
    "    print(f\"Chunk metadata: {doc.metadata}\")\n",
    "    print(f\"Chunk content: {doc.page_content}\")\n",
    "\n",
    "# Playback of the first interval chunked video, should have length 'duration' from first interval\n",
    "Video('video_chunks/chunk_0.mp4', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all VideoChunkLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.langchain_videochunk_loader.VideoChunkLoader.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
